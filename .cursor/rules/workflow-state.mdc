---
description: 
globs: 
alwaysApply: true
---
# workflow_state.md
_Last updated: 2025-06-06_

## State
Phase: ANALYZE
Status: RUNNING
CurrentItem: AI-Assisted Vulnerability Analysis
EpicReference: EPIC-003
EpicPhase: Phase 1: Advanced Vulnerability Detection
EpicStep: AI-ASSISTED_ANALYSIS_STEP

## Plan
### Overview
Implement AI-powered vulnerability analysis system that will enhance the framework's ability to detect and validate security findings using AI models. This includes integrating with AI services, implementing finding analysis, and adding confidence scoring.

### Implementation Steps

1. **AI Service Integration**
   - Create AI service interface
   - Implement OpenAI API integration
   - Add rate limiting and error handling
   - Add configuration management
   - Add service health monitoring
   - Add cost tracking
   - Add fallback mechanisms

2. **Finding Analysis System**
   - Create finding analyzer base class
   - Implement finding metadata extension
   - Add confidence scoring system
   - Add false positive detection
   - Add finding categorization
   - Add finding correlation
   - Add finding prioritization

3. **AI Model Integration**
   - Implement pattern recognition
   - Add natural language processing
   - Add finding summarization
   - Add remediation suggestions
   - Add impact assessment
   - Add risk scoring
   - Add trend analysis

4. **Result Management**
   - Create result storage system
   - Implement result validation
   - Add result aggregation
   - Add result caching
   - Add result versioning
   - Add result export
   - Add result visualization

5. **Testing and Validation**
   - Create test suite
   - Implement integration tests
   - Add performance tests
   - Add accuracy tests
   - Add cost tests
   - Add security tests
   - Add documentation

### File Structure
```
bbf/
├── core/
│   ├── ai/
│   │   ├── __init__.py
│   │   ├── service.py          # AI service interface
│   │   ├── openai.py          # OpenAI integration
│   │   ├── config.py          # AI service configuration
│   │   └── monitoring.py      # Service health monitoring
│   ├── analysis/
│   │   ├── __init__.py
│   │   ├── analyzer.py        # Finding analyzer base
│   │   ├── scoring.py         # Confidence scoring
│   │   ├── validation.py      # Finding validation
│   │   └── correlation.py     # Finding correlation
│   └── models/
│       ├── __init__.py
│       ├── pattern.py         # Pattern recognition
│       ├── nlp.py            # Natural language processing
│       └── assessment.py      # Impact assessment
├── plugins/
│   └── ai_analysis/
│       ├── __init__.py
│       ├── plugin.py          # AI analysis plugin
│       ├── config.py          # Plugin configuration
│       └── templates/         # Analysis templates
└── tests/
    └── ai/
        ├── __init__.py
        ├── test_service.py    # Service tests
        ├── test_analyzer.py   # Analyzer tests
        └── test_models.py     # Model tests
```

### Implementation Details

1. **AI Service Interface**
```python
class AIService:
    """Base class for AI service integration."""
    
    async def analyze_finding(self, finding: Finding) -> AnalysisResult:
        """Analyze a security finding using AI."""
        pass
    
    async def validate_finding(self, finding: Finding) -> ValidationResult:
        """Validate a security finding using AI."""
        pass
    
    async def score_confidence(self, finding: Finding) -> ConfidenceScore:
        """Score the confidence of a finding using AI."""
        pass
```

2. **Finding Analyzer**
```python
class FindingAnalyzer:
    """Base class for finding analysis."""
    
    async def analyze(self, finding: Finding) -> AnalysisResult:
        """Analyze a finding using multiple methods."""
        pass
    
    async def validate(self, finding: Finding) -> ValidationResult:
        """Validate a finding using multiple methods."""
        pass
    
    async def correlate(self, findings: List[Finding]) -> CorrelationResult:
        """Correlate multiple findings."""
        pass
```

3. **AI Model Integration**
```python
class AIModel:
    """Base class for AI model integration."""
    
    async def recognize_patterns(self, data: Any) -> PatternResult:
        """Recognize patterns in data."""
        pass
    
    async def process_text(self, text: str) -> TextAnalysisResult:
        """Process text using NLP."""
        pass
    
    async def assess_impact(self, finding: Finding) -> ImpactAssessment:
        """Assess the impact of a finding."""
        pass
```

### Success Criteria
1. AI service successfully analyzes findings
2. Confidence scoring is accurate and reliable
3. False positive rate is below 5%
4. Analysis is performed in real-time
5. System is cost-effective
6. Documentation is complete
7. Tests pass with good coverage

### Dependencies
- OpenAI API access
- Database for finding storage
- Plugin system for extensibility
- Configuration system
- Logging system
- Monitoring system

### Risks and Mitigations
1. **API Costs**
   - Risk: High API usage costs
   - Mitigation: Implement caching, rate limiting, and cost tracking

2. **Performance**
   - Risk: Slow analysis times
   - Mitigation: Implement caching and parallel processing

3. **Accuracy**
   - Risk: Inaccurate analysis
   - Mitigation: Implement validation and human review options

4. **Reliability**
   - Risk: Service outages
   - Mitigation: Implement fallback mechanisms and health monitoring

### Next Steps
1. Set up AI service interface
2. Implement OpenAI integration
3. Create finding analyzer
4. Add confidence scoring
5. Implement testing

## Rules
> **Keep every major section under an explicit H2 (`##`) heading so the agent can locate them unambiguously.**

### [PHASE: ANALYZE]
1. Read **project_config.md**, relevant code & docs.  
2. **Epic Integration Logic**:
   - If user request mentions epic work (e.g., "work on login from user management epic"), search epics.mdc
   - Identify matching epic, phase, and step from user's natural language description
   - Set CurrentItem to descriptive format, and set epic fields:
     - Set `EpicReference = EPIC_NAME` (if found)
     - Set `EpicPhase = PHASE_NAME` (if found)
     - Set `EpicStep = STEP_NAME` (if found)
   - If no epic context found, leave epic fields as null
3. Summarize requirements. *No code or planning.*

### [PHASE: BLUEPRINT]
1. **Architecture Validation**: Read architecture.mdc to understand current architecture and validate planned changes align with existing patterns and decisions.
2. If `EpicReference` exists, read epic context from epics.mdc for step requirements and acceptance criteria.
3. **Architecture Impact Assessment**: Evaluate if planned work requires architectural changes or updates.
4. Decompose task into ordered steps.  
5. Write pseudocode or file-level diff outline under **## Plan**.
6. **Plan Architecture Updates**: Include steps to update architecture.mdc if architectural changes are being made.
7. Set `Status = NEEDS_PLAN_APPROVAL` and await user confirmation.

### [PHASE: CONSTRUCT]
1. Follow the approved **## Plan** exactly.  
2. After each atomic change:  
   - run test / linter commands specified in `project_config.md`  
   - capture tool output in **## Log**
3. **Architecture Updates**: When implementing architectural changes, update architecture.mdc with new patterns, decisions, or modifications.
4. On success of all steps, set `Phase = VALIDATE`.

### [PHASE: VALIDATE]
1. Rerun full test suite & any E2E checks.  
2. If clean, set `Status = COMPLETED`.  
3. Trigger **RULE_ITERATE_01** when applicable.

---

### RULE_INIT_01
Trigger ▶ `Phase == INIT`  
Action ▶ Ask user for first high-level task → `Phase = ANALYZE, Status = RUNNING`.

### RULE_ITERATE_01
Trigger ▶ `Status == COMPLETED && Items contains unprocessed rows`  
Action ▶  
1. Set `CurrentItem` to next unprocessed row in **## Items**.  
2. Parse epic reference if CurrentItem format is `EPIC_NAME > PHASE_NAME > STEP_NAME`.
3. Clear **## Log**, reset `Phase = ANALYZE, Status = READY`.

### RULE_LOG_ROTATE_01
Trigger ▶ `length(## Log) > 5 000 chars`  
Action ▶ Summarise the top 5 findings from **## Log** into **## ArchiveLog**, then clear **## Log**.

### RULE_EPIC_UPDATE_01
Trigger ▶ `Phase == VALIDATE && Status == COMPLETED && EpicReference != null`
Action ▶
1. Parse EpicReference, EpicPhase, and EpicStep to identify epic location in epics.mdc.
2. Update corresponding epic step status to include completion percentage, date, and notes.
3. Check if all steps in the phase are completed, update phase status accordingly.
4. Add completion entry to epic notes section with timestamp.

### RULE_EPIC_COMPLETION_ARCHIVE_01
Trigger ▶ `Epic Status == COMPLETED in epics.mdc`
Action ▶
1. Identify completed epic(s) in the ACTIVE EPICS section of epics.mdc.
2. Move the completed epic from ACTIVE EPICS section to EPIC COMPLETION HISTORY section.
3. Update portfolio summary counts: decrease Active Epics, increase Completed Epics.
4. Preserve all epic details, phases, steps, and outcomes in the completion history.
5. Update Epic Status Summary section with current counts.
6. Log the epic archival in workflow ## Log section.

### RULE_ARCHITECTURE_UPDATE_01
Trigger ▶ `Phase == CONSTRUCT && architectural changes are being implemented`
Action ▶
1. Identify the architectural change being made (new pattern, technology choice, design decision).
2. Update the relevant section in architecture.mdc with the new information.
3. Add entry to Architecture Changelog with timestamp and change type.
4. Log the architecture update in workflow ## Log section.

### RULE_ARCHITECTURE_VALIDATE_01
Trigger ▶ `Phase == BLUEPRINT && CurrentItem involves architectural decisions`
Action ▶
1. Read current architecture.mdc to understand existing patterns and constraints.
2. Validate that planned changes align with existing architectural decisions.
3. Identify any conflicts with current architecture and note in plan.
4. Include architecture update steps in the plan if new patterns are being introduced.

### RULE_SUMMARY_01
Trigger ▶ `Phase == VALIDATE && Status == COMPLETED`  
Action ▶ 
1. Read `project_config.md`.
2. Construct the new changelog line: `- <One-sentence summary of completed work>`.
3. Find the `## Changelog` heading in `project_config.md`.
4. Insert the new changelog line immediately after the `## Changelog` heading and its following newline (making it the new first item in the list).

---

## Epic Integration Usage

### **Realistic User Interactions**

#### **Starting Epic Work**
```bash
# User says:
"Start working on the login component from the user management epic"

# AI automatically:
1. Searches epics.mdc for user management epic
2. Finds the login component step in authentication phase
3. Sets CurrentItem: "Login component implementation"
4. Sets epic fields:
   EpicReference: USER_MGMT_EPIC
   EpicPhase: AUTHENTICATION_PHASE  
   EpicStep: LOGIN_COMPONENT_STEP
5. Reads epic context during blueprint phase
```

#### **Epic Progress Updates**
```bash
# User says:
"Update the login component progress to 75%, core functionality is done but still need remember me feature"

# AI automatically:
1. Finds current epic work in epics.mdc
2. Updates step status to IN_PROGRESS (75%)
3. Updates notes with user's progress description
4. Sets last updated date
```

#### **Standalone Work (No Epic)**
```bash
# User says:
"Fix the payment processing bug in checkout"

# AI automatically:
1. No epic context mentioned, processes as standalone work
2. Sets CurrentItem: "Fix payment processing bug"
3. Leaves epic fields null:
   EpicReference: null
   EpicPhase: null
   EpicStep: null
```

### **AI Epic Management Commands**
The AI handles these natural language requests:
- **"Plan an epic for [feature]"** → Creates new epic in epics.mdc
- **"Work on [step] from [epic]"** → Starts workflow with epic context
- **"Update progress on [current work]"** → Updates epic step status
- **"Mark [step] as complete"** → Sets step to 100% and updates epic
- **"Show epic status"** → Displays current epic progress

---

## Items
| id | description | status |
|----|-------------|--------|
| 1 | AI Service Integration | PLANNED |
| 2 | Finding Analysis System | PLANNED |
| 3 | AI Model Integration | PLANNED |
| 4 | Result Management | PLANNED |
| 5 | Testing and Validation | PLANNED |

## Log
[2024-03-21 11:00:00] Started planning Phase 1 of EPIC-003
[2024-03-21 11:05:00] Created implementation plan for AI-assisted analysis
[2024-03-21 11:10:00] Defined file structure and component interfaces

## ArchiveLog
<!-- RULE_LOG_ROTATE_01 stores condensed summaries here -->

## Changelog
<!-- RULE_SUMMARY_01 stores the new changelog line here -->
